{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "logocGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ralls0/logocGAN/blob/ral%2Fbup/logocGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF72avp2AybM"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from imutils import build_montages\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "from tensorflow.keras import Sequential, Model, Input\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow import keras\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvAiLmS1bCYE",
        "outputId": "0424b3b0-f15d-45e1-9372-052c40b76e2a"
      },
      "source": [
        "# mount google Drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment"
      ],
      "metadata": {
        "id": "AtZ6YXrhWt9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# env\n",
        "NUM_DIMS=100                      # Number of dimension manipulated into the lateted space \n",
        "BATCH_SIZE=64                     #\n",
        "INIT_LR=2e-4                      # Learning rate\n",
        "image_size = (256,256)            #\n",
        "noise = Input((NUM_DIMS))         # \n",
        "BATCH_SIZE_2 = BATCH_SIZE // 2\n",
        "NUM_EPOCHS=300\n",
        "\n",
        "directory=\"/content/drive/MyDrive/Politecnico/logo\"\n",
        "base_class=\"/1\"\n",
        "directory_models=\"/content/drive/MyDrive/Politecnico/gen/\""
      ],
      "metadata": {
        "id": "dozuWbqdWlKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "ISEdnmVgVyLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate random points in the latent space\n",
        "# in this case, we are using a Gaussian (normal) distribution with 0 mean and 1.\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\n",
        "\tx_input = np.random.randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input"
      ],
      "metadata": {
        "id": "1Al93ibrYyEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess the images so that they are in the range [-1, 1]\n",
        "# the range of the real images should be the same of the fake images \n",
        "\n",
        "def preprocessing_function(x):\n",
        "  return (x - 127.5)/127.5"
      ],
      "metadata": {
        "id": "kIOIFVBUcxBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function to plot some figures\n",
        "def plot_figures(x, n, figsize=None):\n",
        "  if figsize:\n",
        "      plt.figure(figsize=figsize)\n",
        "  for i in range(n*n):\n",
        "      plt.subplot(n,n,i+1)\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])\n",
        "      plt.grid(False)\n",
        "      img=x[i,:,:,:]\n",
        "      # rescale for visualization purposes\n",
        "      img = ((img*127.5) + 127.5).astype(\"uint8\")\n",
        "      plt.imshow(img)\n",
        "    \n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "NQ7IkJrseYek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function to store some figures\n",
        "def store_figures(x, n, directory, epoch):\n",
        "  for i in range(n*n):\n",
        "    img=x[i,:,:,:]\n",
        "    # rescale for visualization purposes\n",
        "    img = ((img*127.5) + 127.5).astype(\"uint8\")\n",
        "    cv2.imwrite(os.path.join(directory, \"dcgan_img_gen-\" + str(epoch) + \"-\" + str(i) + \".png\"), img)"
      ],
      "metadata": {
        "id": "HCbjmPZFedfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility function to plot loss figures\n",
        "def plot_losses(history, lim):\n",
        "  pandas.DataFrame(history).plot(figsize=(10,8))\n",
        "  plt.grid(True)\n",
        "  plt.gca().set_ylim(0,lim)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Abz6JXpana4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jGvoOuMBQF9"
      },
      "source": [
        "# Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNXm4_XTBPzG"
      },
      "source": [
        "def build_generator(width, height, inputDim=100, n1=2048, channels=3):\n",
        "\n",
        "  inp = Input(shape=(inputDim,))\n",
        "\n",
        "  # FC - BN \n",
        "  dim1 = width // 16      # because we have 4 transpose conv layers with strides 2 -> \n",
        "  dim2 = height // 16     # -> we are upsampling by a factor of 64\n",
        "  \n",
        "  x = Dense( dim1 * dim2 * n1, activation=\"relu\")(inp)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  # Reshape to width * heigh * feature_channels\n",
        "\n",
        "  x = Reshape((dim1, dim2,n1))(x)\n",
        "\n",
        "\n",
        "  # Conv 2D transpose\n",
        "  x = Conv2DTranspose(n1//2, (5, 5), strides=(2, 2), padding=\"same\", activation=\"relu\")(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = Conv2DTranspose(n1//4, (5, 5), strides=(2, 2), padding=\"same\", activation=\"relu\")(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = Conv2DTranspose(n1//8, (5, 5), strides=(2, 2), padding=\"same\", activation=\"relu\")(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  \n",
        "  # Final layer with tanh activation\n",
        "  out = Conv2DTranspose(channels, (5,5), strides=(2,2), padding=\"same\", activation=\"tanh\")(x)\n",
        "\n",
        "  m = Model(inputs=inp, outputs=out)\n",
        "  return m\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q8rC_x-FFfZ"
      },
      "source": [
        "# builds a discriminator with 3 convolutional layers\n",
        "\n",
        "def build_discriminator(width, height, channels, alpha=0.2, droprate=0.4):\n",
        "    input_shape = (width, height, channels)\n",
        "\n",
        "    # use Leaky ReLU instead of Relu in the discriminator\n",
        "    leaky = tf.keras.layers.LeakyReLU(alpha)\n",
        "    n1 = 128\n",
        "    n2 = 256\n",
        "    n3 = 512\n",
        "\n",
        "    inp = Input(shape=input_shape)\n",
        "    x = Conv2D(n1, (5,5), strides=(2,2), activation=leaky)(inp)\n",
        "    x = Conv2D(n2, (5,5), strides=(2,2), activation=leaky)(x)\n",
        "    x = Conv2D(n3, (3,3), strides=(2,2), activation=leaky)(x)\n",
        "   \n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Increase variability in the discriminator by means of `Dropout`\n",
        "    x = Dropout(droprate)(x)\n",
        "    out = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    m = Model(inputs=inp, outputs=out)\n",
        "    return m\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compiling models"
      ],
      "metadata": {
        "id": "R3xMoWK_nr2F"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAYJci_BBbVO"
      },
      "source": [
        "# Generator\n",
        "gen = build_generator(image_size[0], image_size[1], inputDim=NUM_DIMS, n1=2048, channels=3)\n",
        "gen.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyMygib9HHHE"
      },
      "source": [
        "# Discriminator\n",
        "disc = build_discriminator(image_size[0], image_size[1], 3, droprate=0.5)\n",
        "disc.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thRFYB-pH0MK"
      },
      "source": [
        "# Compile the discriminator\n",
        "discOpt = tf.keras.optimizers.Adam(lr=INIT_LR, beta_1=0.5)                # beta_1 was could achieve best performances with Adam\n",
        "disc.compile(discOpt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "disc.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O3P2km9XRdE"
      },
      "source": [
        "# Connecting the two models\n",
        "\n",
        "# Setting the discriminator to not trainable\n",
        "disc.trainable = False\n",
        "\n",
        "# Connecting the discriminator with the generator\n",
        "discOutput=disc(gen(noise))\n",
        "gan = Model(inputs=noise, outputs=discOutput)\n",
        "\n",
        "ganOpt = tf.keras.optimizers.Adam(lr=INIT_LR, beta_1=0.5)\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=ganOpt)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb3VAkMGYs2p"
      },
      "source": [
        "gan.summary()\n",
        "disc.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qtza8GGHfKT"
      },
      "source": [
        "# noise vector used during training in order to evaluate how the network is learning\n",
        "benchmarkNoise = generate_latent_points(NUM_DIMS, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYk37pd8b6uA"
      },
      "source": [
        "train_generator = keras.preprocessing.image.ImageDataGenerator(\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    preprocessing_function=preprocessing_function\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIebH6vrc3LK",
        "outputId": "8bf47f56-a75c-4fd3-b854-d65ac948695c"
      },
      "source": [
        "training_size = len(os.listdir(directory+base_class) )\n",
        "print(f\" Traning size: {training_size}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJdHgvL9cW4V",
        "outputId": "b4931767-f517-4183-a61a-e4fff2c529cd"
      },
      "source": [
        "train = train_generator.flow_from_directory(directory, target_size=image_size, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1940 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQEZp7GpJT6E"
      },
      "source": [
        "# Training for a given number of epochs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrqSchRdeI5X",
        "outputId": "e5760cf3-fc81-4c01-ef7e-34b35e5441ab"
      },
      "source": [
        "trueImages, _ = next(train)\n",
        "trueImages.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 256, 256, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5MCZGy-h_v6",
        "outputId": "35ce23b6-1887-4263-ad4d-39adea1daaf8"
      },
      "source": [
        "batchesPerEpoch = int(training_size / BATCH_SIZE)\n",
        "print(f\" Batches per epoch: {batchesPerEpoch}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yR1A6PJUJXOs"
      },
      "source": [
        "#keep track of loss and accuracy separately for true and fake images\n",
        "history = {}\n",
        "history['G_loss'] = []\n",
        "history['D_loss_true'] = []\n",
        "history['D_loss_fake'] = []\n",
        "\n",
        "accuracy = {}\n",
        "accuracy['Acc_true'] = []\n",
        "accuracy['Acc_fake'] = []\n",
        "\n",
        "# for each epoch\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  batchesPerEpoch = int(training_size / BATCH_SIZE)\n",
        "  q = 1\n",
        "  now = datetime.now()\n",
        "  current_time = now.strftime(\"%H:%M:%S\")\n",
        "  print(f\"[i] ({current_time}) Epoch {epoch} [\", end =\"\")\n",
        "\n",
        "  # for each batch\n",
        "  for b in (range(1, batchesPerEpoch+1)):\n",
        "    if ((b*10/batchesPerEpoch) % q ) == 0:\n",
        "      q=q+1\n",
        "      print(\"=\", end =\"\")\n",
        "\n",
        "    # Training the discriminator to differentiate between true and fake images\n",
        "    trueImages, _ = next(train)\n",
        "\n",
        "    # One sided label smoothing reduces overconfidence in true images and stabilizes training a bit\n",
        "    y = 0.9*np.ones((trueImages.shape[0]))\n",
        "    discLoss, discAcc = disc.train_on_batch(trueImages, y)\n",
        "    \n",
        "    history['D_loss_true'].append(discLoss)    \n",
        "\n",
        "    # Warning: accuracy will not be calculated if label smoothing is used \n",
        "    accuracy['Acc_true'].append(discAcc)\n",
        "    \n",
        "    # Generating some fake samples\n",
        "    noise =  generate_latent_points(NUM_DIMS, BATCH_SIZE)\n",
        "    genImages=gen.predict(noise)\n",
        "    y = np.zeros((BATCH_SIZE))\n",
        "\n",
        "    discLoss, discAcc = disc.train_on_batch(genImages, y)\n",
        "    history['D_loss_fake'].append(discLoss)          \n",
        "    accuracy['Acc_fake'].append(discAcc)\n",
        "\n",
        "    # Training the generator\n",
        "    noise =  generate_latent_points(NUM_DIMS, BATCH_SIZE)\n",
        "\n",
        "    # NOTE: Some authors suggest randomly flipping some labels to introduce random variations\n",
        "    fake_labels = [1] * BATCH_SIZE\n",
        "    fake_labels = np.reshape(fake_labels, (-1,))\n",
        "    ganLoss = gan.train_on_batch(noise, fake_labels)\n",
        "    \n",
        "    history['G_loss'].append(ganLoss)\n",
        "\n",
        "  print(\"]:\", end=\" \")\n",
        "  print(f\"Discriminator loss {str(discLoss)} ( {str(discAcc)} ) - Generator loss {str(ganLoss)}\")\n",
        "\n",
        "  images = gen.predict(benchmarkNoise)\n",
        "\n",
        "  # Visualizing the output\n",
        "  if (epoch % 10) == 0:\n",
        "    store_figures(images, 4, directory_models, epoch)\n",
        "    plot_figures(images, 4)\n",
        "\n",
        "\n",
        "  # Saving\n",
        "  if (epoch % 100) == 0:\n",
        "    gan.save(os.path.join(directory_models, \"logocGAN_\" + str(epoch)+\".h5\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting metrics"
      ],
      "metadata": {
        "id": "BFRyh8-ln4s7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1PIrI3eIUA8"
      },
      "source": [
        "plot_losses(history, 3)\n",
        "plot_losses(accuracy, 1)\n",
        "plot_figures(trueImages, 4, figsize=(10, 10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvnxmMMHqQpd"
      },
      "source": [
        "# Reloading the model at the selecte epoch\n",
        "\n",
        "epoch = 200\n",
        "leaky = tf.keras.layers.LeakyReLU(0.2)\n",
        "tf.keras.utils.get_custom_objects().update({'LeakyReLU': leaky})\n",
        "gan = tf.keras.models.load_model(os.path.join(directory_models, \"dcgan_2\" + str(epoch)+\".h5\"))\n",
        "\n",
        "gen = gan.layers[1]\n",
        "\n",
        "gen.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeQzM3yyOFcj"
      },
      "source": [
        "noisevector = generate_latent_points(NUM_DIMS, BATCH_SIZE)\n",
        "\n",
        "genImages = gen.predict(noisevector)    \n",
        "plot_figures(genImages,4, figsize=(10, 10))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}